{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSet(Dataset):\n",
    "\n",
    "    def __init__(self, samples, step=100):\n",
    "        self.data = np.zeros((len(samples), step))\n",
    "        self.target = np.zeros(len(samples), dtype=np.float32)\n",
    "        raw_data = json.load(open('data/prop_span.json'))\n",
    "        for i, sample in enumerate(samples):\n",
    "            span = raw_data[sample]\n",
    "            volumn = map(lambda x: int(x * step / 8.1), np.log10(span))\n",
    "            for item in volumn:\n",
    "                self.data[i][item] += 1\n",
    "            if 'rumor' in sample:\n",
    "                self.target[i] = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.data[idx]).float(), self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, 3, padding=1)\n",
    "        self.fc_in = input_size // 4 * 16\n",
    "        self.fc1 = nn.Linear(self.fc_in, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), 2))\n",
    "        x = F.dropout(x.view(-1, self.fc_in), training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=64, bidirectional=True):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size * self.n_directions, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = self._init_hidden_state(x.size(0))\n",
    "        x, hn = self.rnn(x, h0)\n",
    "        x = self.fc(F.dropout(x[:, -1, :], training=self.training))\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "    def _init_hidden_state(self, batch_size):\n",
    "        h0 = torch.zeros(self.n_directions, batch_size, self.hidden_size)\n",
    "        if use_gpu:\n",
    "            h0 = h0.cuda()\n",
    "        return Variable(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, step_size, n_epoch=20):\n",
    "\n",
    "    if use_gpu:\n",
    "        model.cuda()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "    model_type = model.__class__.__name__\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch %03d:' % (epoch + 1))\n",
    "        tr_loss, val_loss, tr_acc, val_acc = 0.0, 0.0, 0.0, 0.0\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            if model_type == 'RNN':\n",
    "                data = data.view(data.size(0), -1, step_size)\n",
    "            elif model_type == 'CNN':\n",
    "                data = data.view(data.size(0), 1, -1)\n",
    "            target = target.view(target.size(0), 1)\n",
    "            optimizer.zero_grad()\n",
    "            if use_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_loss += loss.data[0] * data.size(0)\n",
    "            pred = torch.sign(output.data - 0.5).clamp_(min=0)\n",
    "            tr_acc += pred.eq(target.data).cpu().sum()\n",
    "        tr_loss /= len(train_loader.dataset)\n",
    "        tr_acc = tr_acc / len(train_loader.dataset) * 100\n",
    "        print(f'tr_loss {tr_loss:.6f} | tr_acc {tr_acc:.2f}%')\n",
    "\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            if model_type == 'RNN':\n",
    "                data = data.view(data.size(0), -1, step_size)\n",
    "            elif model_type == 'CNN':\n",
    "                data = data.view(data.size(0), 1, -1)\n",
    "            target = target.view(target.size(0), 1)\n",
    "            if use_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.data[0] * data.size(0)\n",
    "            pred = torch.sign(output.data - 0.5).clamp_(min=0)\n",
    "            val_acc += pred.eq(target.data).cpu().sum()\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "        val_acc = val_acc / len(test_loader.dataset) * 100\n",
    "        print(f'val_loss {val_loss:.6f} | val_acc {val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = glob('rumor/*.json') + glob('truth/*.json')\n",
    "train_data, test_data = train_test_split(samples, test_size=0.2, random_state=42)    \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "train_loader = DataLoader(DSet(train_data), batch_size=128, **kwargs)\n",
    "test_loader = DataLoader(DSet(test_data), batch_size=128, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001:\n",
      "tr_loss 0.734407 | tr_acc 59.42%%\n",
      "val_loss 0.588298 | val_acc 66.99%%\n",
      "Epoch 002:\n",
      "tr_loss 0.473139 | tr_acc 79.74%%\n",
      "val_loss 0.505089 | val_acc 76.31%%\n",
      "Epoch 003:\n",
      "tr_loss 0.443367 | tr_acc 81.24%%\n",
      "val_loss 0.507804 | val_acc 78.14%%\n",
      "Epoch 004:\n",
      "tr_loss 0.419608 | tr_acc 82.50%%\n",
      "val_loss 0.494735 | val_acc 78.78%%\n",
      "Epoch 005:\n",
      "tr_loss 0.411384 | tr_acc 82.50%%\n",
      "val_loss 0.453101 | val_acc 80.49%%\n",
      "Epoch 006:\n",
      "tr_loss 0.394824 | tr_acc 83.68%%\n",
      "val_loss 0.464016 | val_acc 80.81%%\n",
      "Epoch 007:\n",
      "tr_loss 0.373539 | tr_acc 84.59%%\n",
      "val_loss 0.473353 | val_acc 81.03%%\n",
      "Epoch 008:\n",
      "tr_loss 0.359102 | tr_acc 85.12%%\n",
      "val_loss 0.479471 | val_acc 80.49%%\n",
      "Epoch 009:\n",
      "tr_loss 0.341588 | tr_acc 86.01%%\n",
      "val_loss 0.487963 | val_acc 79.31%%\n",
      "Epoch 010:\n",
      "tr_loss 0.329585 | tr_acc 86.46%%\n",
      "val_loss 0.489413 | val_acc 81.46%%\n"
     ]
    }
   ],
   "source": [
    "train(RNN(10), 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RNN'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
